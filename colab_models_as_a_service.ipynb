{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheRealFREDP3D/Coding-Exercises/blob/main/colab_models_as_a_service.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWzdSztXWcpg"
      },
      "source": [
        "# Colab AI: List available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ucchuu5vV3Jp",
        "outputId": "1ec1cf1f-63ff-4705-a75f-34876a51b7f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['google/gemini-2.5-flash', 'google/gemini-2.5-flash-lite']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "ai.list_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjfCGEpzDsD9"
      },
      "source": [
        "The model names give you a hint about their capabilities and intended use:\n",
        "\n",
        "Pro: These are the most capable models, ideal for complex reasoning, creative tasks, and detailed analysis.\n",
        "\n",
        "Flash: These models are optimized for high speed and efficiency, making them great for summarization, chat applications, and tasks requiring rapid responses.\n",
        "\n",
        "Gemma: These are lightweight, open-weight models suitable for a variety of text generation tasks and are great for experimentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oypl6kfOX9Jw"
      },
      "source": [
        "# Colab AI: Choose a different model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NHO9VzO9AHZP",
        "outputId": "e817204b-7ac0-46d2-81af-53c10bf611a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of England is **London**.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "\n",
        "response = ai.generate_text(\"What is the capital of England\", model_name='google/gemini-2.5-flash-lite')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpUByA5CYQTa"
      },
      "source": [
        "# Colab AI: Simple batch generation example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0rmsI9zYJ-o"
      },
      "outputs": [],
      "source": [
        "# Only text-to-text input/output is supported\n",
        "from google.colab import ai\n",
        "\n",
        "response = ai.generate_text(\"What is the capital of France?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJPCM4cYawP"
      },
      "source": [
        "# Colab AI: Simple streaming example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BNgxiB6--_5"
      },
      "outputs": [],
      "source": [
        "from google.colab import ai\n",
        "\n",
        "stream = ai.generate_text(\"Tell me a short story.\", stream=True)\n",
        "for text in stream:\n",
        "  print(text, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBJk0a4rY-n1"
      },
      "source": [
        "# Colab AI: Formatted streaming example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpMmpaVClSBV"
      },
      "outputs": [],
      "source": [
        "#code is not necessary for colab.ai, but is useful in fomatting text chunks\n",
        "import sys\n",
        "from google.colab import ai\n",
        "\n",
        "\n",
        "class LineWrapper:\n",
        "    def __init__(self, max_length=80):\n",
        "        self.max_length = max_length\n",
        "        self.current_line_length = 0\n",
        "\n",
        "    def print(self, text_chunk):\n",
        "        i = 0\n",
        "        n = len(text_chunk)\n",
        "        while i < n:\n",
        "            start_index = i\n",
        "            while i < n and text_chunk[i] not in ' \\n': # Find end of word\n",
        "                i += 1\n",
        "            current_word = text_chunk[start_index:i]\n",
        "\n",
        "            delimiter = \"\"\n",
        "            if i < n: # If not end of chunk, we found a delimiter\n",
        "                delimiter = text_chunk[i]\n",
        "                i += 1 # Consume delimiter\n",
        "\n",
        "            if current_word:\n",
        "                needs_leading_space = (self.current_line_length > 0)\n",
        "\n",
        "                # Case 1: Word itself is too long for a line (must be broken)\n",
        "                if len(current_word) > self.max_length:\n",
        "                    if needs_leading_space: # Newline if current line has content\n",
        "                        sys.stdout.write('\\n')\n",
        "                        self.current_line_length = 0\n",
        "                    for char_val in current_word: # Break the long word\n",
        "                        if self.current_line_length >= self.max_length:\n",
        "                            sys.stdout.write('\\n')\n",
        "                            self.current_line_length = 0\n",
        "                        sys.stdout.write(char_val)\n",
        "                        self.current_line_length += 1\n",
        "                # Case 2: Word doesn't fit on current line (print on new line)\n",
        "                elif self.current_line_length + (1 if needs_leading_space else 0) + len(current_word) > self.max_length:\n",
        "                    sys.stdout.write('\\n')\n",
        "                    sys.stdout.write(current_word)\n",
        "                    self.current_line_length = len(current_word)\n",
        "                # Case 3: Word fits on current line\n",
        "                else:\n",
        "                    if needs_leading_space:\n",
        "                        # Define punctuation that should not have a leading space\n",
        "                        # when they form an entire \"word\" (token) following another word.\n",
        "                        no_leading_space_punctuation = {\n",
        "                            \",\", \".\", \";\", \":\", \"!\", \"?\",        # Standard sentence punctuation\n",
        "                            \")\", \"]\", \"}\",                     # Closing brackets\n",
        "                            \"'s\", \"'S\", \"'re\", \"'RE\", \"'ve\", \"'VE\", # Common contractions\n",
        "                            \"'m\", \"'M\", \"'ll\", \"'LL\", \"'d\", \"'D\",\n",
        "                            \"n't\", \"N'T\",\n",
        "                            \"...\", \"â€¦\"                          # Ellipses\n",
        "                        }\n",
        "                        if current_word not in no_leading_space_punctuation:\n",
        "                            sys.stdout.write(' ')\n",
        "                            self.current_line_length += 1\n",
        "                    sys.stdout.write(current_word)\n",
        "                    self.current_line_length += len(current_word)\n",
        "\n",
        "            if delimiter == '\\n':\n",
        "                sys.stdout.write('\\n')\n",
        "                self.current_line_length = 0\n",
        "            elif delimiter == ' ':\n",
        "                # If line is full and a space delimiter arrives, it implies a wrap.\n",
        "                if self.current_line_length >= self.max_length:\n",
        "                    sys.stdout.write('\\n')\n",
        "                    self.current_line_length = 0\n",
        "\n",
        "        sys.stdout.flush()\n",
        "\n",
        "\n",
        "wrapper = LineWrapper()\n",
        "for chunk in ai.generate_text('Give me a long winded description about the evolution of the Roman Empire.', model_name='google/gemini-2.0-flash', stream=True):\n",
        "  wrapper.print(chunk)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab_models_as_a_service.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}